\subsection*{Focus Area 3:  Robust models for geometric and topological inference}%, clustering and comparison}


%Remarques a inserer dans l'intro generale du projet (version longue, plus eventuellement version courte):
%
%- La majorite des donnees proviennent de simulations ou de prises mesures.  Elles sont generalement corrompues par du bruit, des outliers, et elles sont souvent parcellaires. Il est donc %important de disposer de techniques permettant de reparer ces defauts, ou bien directement de methodes d'analyse qui n'y soient pas sensibles.
%
%- Le fait de considerer des donnees en grandes dimensions ou dans des espaces "compliques" empeche l'exploration visuelle directe des donnees, mais egalement la validation visuelle des %resultats obtenus par l'analyse. Il y a donc besoin de methodes de visualisation de la structure de telles donnees qui viennent avec des garanties sur la pertinence des resultats, de sorte que %l'on soit assure que ce qui est montre par ces methodes est bien de l'information et non du bruit.



%\paragraph{Noise models.}
% Assuming that the data are corrupted by noise of small amplitude successful robust methods have been proposed for the estimation of topological and geometric  properties of shapes. They are usually based on the study of the topology of the level sets of the distance function to the data that can be related to the topology of the underlying shape when the Hausdorff distance  between the data and the shape is small enough (small amplitude noise). As previously mentioned such an assumption on the noise does not comply with many applications where the data come corrupted by non local noise. 
% %Moreover most of the methods relying on the closeness of the data to the shape with respect to the Hausdorff distance are deterministic and do not take into account the statistical nature of the %noise.  
% Recently more statistical approaches allowing to deal with larger classes of noise models have been considered to infer geometric information from data. Some of them intend to remove the part of the data that is far away from the underlying shape and to make use of  the distance function framework \cite{nsw-tvu-2011} but they assume very restrictive noise models. On another hand purely statistical approaches have been proposed for shape approximation that work for large families of noise models (see, e.g., \cite{gpvw-mme-2011,gpvw-mesd-2011}) but they do not come with topological guarantees on the approximated geometric shapes and do not always provide explicit estimates. A major remaining challenge is the design of new unifying frameworks that embrace the statistical approaches and the deterministic methods coming with topological guarantees.  
% This is a goal we set to ourselves in this project for three different central problems: homology inference, clustering, and signature design.


%We intend to develop practically efficient tools for robust topological and geometric inference that work with large classes of models of noise. 


The goal is to infer geometric and topological properties from defect-laden data.
 A major challenge is to combine  statistical approaches relying on powerful models of noise and deterministic methods coming with topological guarantees.  
% This is a goal we set to ourselves in this project for three different central problems: homology inference, clustering, and signature design.

%\framebox{on ne parle plus de stat ensuite}


\paragraph{Homology inference.}
Building on the distance function approach, algorithms have been developed to infer the homology of general shapes from \v{C}ech or Rips complexes built on top of the data. 
These algorithms are efficient and stable under small Hausdorff noise~\cite{co-tpr-2008}. The basic idea is that the topology of the sampled shape is carried by the topology of the sublevel sets of the distance function to the data points, which in turn is  related to the topology of the \v{C}ech and the Rips complexes. 
%$\alpha$-shape \framebox{not defined before. really needed?} and Rips complexes.  

To comply with the presence of noise and outliers in the data, we intend to explore different approaches inspired from these algorithms.  We will in particular focus on a new paradigm for point cloud data analysis that was recently proposed by researchers from my group. Point clouds are no longer considered as mere compact sets but rather as {\em empirical measures}. A notion of distance to such probability measures has been defined and shown to be stable with respect to perturbations of the probability measure \cite{ccsm-gipm-2011}. It has also been shown that the sublevel sets of this distance function carry the geometric information about the probability measure. If we consider a model where the data is generated from a probability distribution on a shape corrupted by some noise, the sublevel-sets then carry the information about the shape itself.
The distance to an empirical measure can easily be computed pointwise in the case of a point cloud (by averaging the squared distances to the $k$ nearest neighbors). Unfortunately, the sublevel-sets remain hard to compute or approximate, and a
challenge is to design efficient algorithms to compute or approximate them  in high dimensions. Such algorithms would naturally find applications in topological inference in the presence of significant noise and outliers, but also in other less obvious contexts such as stable clustering. The current bottleneck stems from the fact that there exists no equivalent of a union of balls nor of \v{C}ech complexes for the distance to a measure. Our first goal will be to work out such equivalents that will allow to infer the homology of the underlying shape or more generally the topological persistence of the distance to measure functions.
%To start with, we will focus on
%medium dimensions and use a variant of the mesh-based inference algorithm [14] to approximate
%the sublevel-sets of the distance to a measure and get an idea of their topological structure.

Remarkably, the measure-theoretic approach adopted to introduce and study the distance to a measure is well suited to take the statistical nature of data into account and to develop inference models that combine statistical and geometric methods. This new framework opens promising new research directions. It has already given rise to fruitful applications in density estimation, providing topological guarantees on the level sets of the density estimates \cite{bccdr-wknde-11},  and  in geometric deconvolution allowing the recovery of  topological features of shapes sampled with a huge amount of (known) noise  \cite{ccdm-dwmgi-11}.

\paragraph{Clustering with a geometric prior.} %\framebox{add ref}
Clustering may be viewed as the most basic homology inference problem, since it consists in inferring the connected components in the data set. Typical methods for clustering data sets in high dimensions, {\it e.g.,} spectral clustering \cite{sm-ncis-97}, work well under three specific assumptions. First, the clusters should be sufficiently connected, for example, the second eigenvalue of their graph Laplacian should be large enough. Second, they should be well separated, that is, the interpoint distances between different clusters should be large enough on average. Third, the clusters should be balanced enough. We intend to develop methods that would take advantage of situations where the clusters have additional properties, such as being nearly convex or smooth, which seems reasonable in the large number of cases where manifold learning techniques apply. A promising strategy would be to use geometric regularity measures stemming from the geometric sampling theory recently introduced in my group\cite{geometrica-ccl09}. One challenge is to design these regularity measures in such a way that they are both easy to compute and amenable to classical clustering strategies. We expect the resulting clustering schemes to outperform classical spectral clustering when the data exhibit some form of geometric regularity. Byproducts of this effort could also lead to efficient algorithms for assessing the degree of geometric regularity present in real data. 



\paragraph{Topological signatures for shapes.}

% Shape descriptors are used in a variety of applications, including 
% shape classification, shape retrieval, shape matching, shape
% registration, and symmetry detection. % In the context of this proposal,
% the word {\em shape} must be understood in a very broad sense: for
% instance, it can be a point cloud, or a
% manifold, or more generally a compact metric space.

Using topological quantities deduced from measurements to design signatures for shapes
is a relatively new idea. The bottom line of the approach is the
following: given a finite sampling of the shape, build some filtered
simplicial complex on top of the point cloud, and use the topological
structure of this filtration (encoded as a planar diagram called a
{\em persistence diagram}) as a signature for the point
cloud~\cite{ccgmo-ghsssp-09, socg-pbsds-10}. This construction is
well-suited to finite metric spaces, and the obtained signatures are
known to be stable under small perturbations of the spaces in the
Gromov-Hausdorff distance.  
As in many applications data only come with a measure of similarity between the pairs of data points  (that does not satisfy the triangle equality), 
a major remaining challenge is to extend the construction to {\em general spaces endowed with a similarity measure},
%A major remaining challenge is to extend the construction to {\em infinite metric spaces} \framebox{motivation?}, 
and to prove the stability of
its topological structure with respect to perturbations of the space
in some Gromov-Hausdorff-like distance.

A more fundamental question is how much information about a shape can
be recovered from descriptors. As discussed in the state of the art,
% Most existing work in shape analysis
% only provides lower bounds on a shape distance (e.g. the
% Gromov-Hausdorff distance) based on descriptor distance. There are
% very few exceptions to this rule, and the upper bounds on shape
% distances these provide come with very loose guarantees on the
% error~\cite{bbk-gmds-06,ms-gh-05}. D
deriving tight upper bounds on shape distances based on shape descriptors is
still widely open, and we intend to tackle the problem as
follows: thanks to the virtually infinite variety of filtrations that
can be built on top of a shape, it is easy to enrich the pool of
signatures used for that shape, and thus restrict the possibility of
false positives in the shape comparison process. It is then a question
of how large a family of filtrations is required to guarantee that
different shapes do get different signatures. From an algorithmic
perspective, the problem comes down to identifying small samplings of this
family of filtrations that can be used as proxies for a better (if not
perfect) assessment of the similarity between two shapes.  As we
intend to consider our signatures on large sets of shapes, it will
also be important to design algorithms to efficiently compute these
signatures and to compare them.% \framebox{shall we put a ref to
%  another WP where fast bottleneck distance computation/approximation
%  would be considered?}

Finally, the difficulty of matching two shapes is
intimately tied to matching a shape to itself --- shapes with many
natural self maps (symmetries) can be difficult to match because of
the ambiguities symmetries create (reflected in duplicate descriptors,
etc.). It may be interesting to define the analog of a {\em condition
  number} for a shape, which would capture the intrinsic difficulty of
characteristic or matching against that shape.



