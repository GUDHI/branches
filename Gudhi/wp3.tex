\subsection*{Focus Area 3:  Robust models for geometric inference, comparison and  clustering}


%Remarques a inserer dans l'intro generale du projet (version longue, plus eventuellement version courte):
%
%- La majorite des donnees proviennent de simulations ou de prises mesures.  Elles sont generalement corrompues par du bruit, des outliers, et elles sont souvent parcellaires. Il est donc %important de disposer de techniques permettant de reparer ces defauts, ou bien directement de methodes d'analyse qui n'y soient pas sensibles.
%
%- Le fait de considerer des donnees en grandes dimensions ou dans des espaces "compliques" empeche l'exploration visuelle directe des donnees, mais egalement la validation visuelle des %resultats obtenus par l'analyse. Il y a donc besoin de methodes de visualisation de la structure de telles donnees qui viennent avec des garanties sur la pertinence des resultats, de sorte que %l'on soit assure que ce qui est montre par ces methodes est bien de l'information et non du bruit.



%\paragraph{Noise models.}
Assuming that the data are corrupted by noise of small amplitude successful robust methods have been proposed for the estimation of topological and geometric  properties of shapes. They are usually based on the study of the topology of the level sets of the distance function to the data that can be related to the topology of the underlying shape when the Hausdorff distance  between the data and the shape is small enough (small amplitude noise). As previously mentioned such an assumption on the noise does not comply with many applications where the data come corrupted by non local noise. 
%Moreover most of the methods relying on the closeness of the data to the shape with respect to the Hausdorff distance are deterministic and do not take into account the statistical nature of the %noise.  
Recently more statistical approaches allowing to deal with larger classes of noise models have been considered to infer geometric information from data. Some of them intend to remove the part of the data that is far away from the underlying shape and to make use of  the distance function framework \cite{nsw-tvu-2011} but they assume very restrictive noise models. On another hand purely statistical approaches have been proposed for shape approximation that work for large families of noise models (see, e.g., \cite{gpvw-mme-2011,gpvw-mesd-2011}) but they do not come with topological guarantees on the approximated geometric shapes and do not always provide explicit estimates. A major remaining challenge is the design of new unifying frameworks that embrace the statistical approaches and the deterministic methods coming with topological guarantees.  
This is a goal we set to ourselves in this project for three different central problems: homology inference, clustering, and signature design.


%We intend to develop practically efficient tools for robust topological and geometric inference that work with large classes of models of noise. 


\paragraph{Homology inference.}
Building on the distance function approach efficient and guaranteed algorithms have been developed to infer the homology of general shapes from \v{C}ech or Rips complexes built on top of the data when they are sampled at a small Hausdorff distance of the considered shape \cite{co-tpr-2008}. These algorithms rely on  the idea that the topology of the shape is carried  by the topology of some  unions of balls centered on the data (i.e. the sublevel sets of the distance function to the data)  that can itself be related to the topology of the  alpha-shape and Rips complexes.
To comply with the presence of noise and outliers in the data we will to explore different approaches inspired from these algorithms. 
We will in particular focus on a new paradigm for point cloud data analysis that has emerged recently, where point clouds are no
longer treated as mere compact sets but rather as empirical measures. A notion of distance to
such measures has been defined and shown to be stable with respect to perturbations of the
measure \cite{ccsm-gipm-2011}. This distance can easily be computed pointwise in the case of a point cloud (simply
average the squared distances to the $k$ nearest neighbors), but its sublevel-sets, which carry the
geometric information about the measure (or the underlying shape if we consider a model where the data is generated from a measure on the shapes corrupted by some noise), remain hard to compute or approximate. A big challenge now is to find efficient algorithms in arbitrary dimensions to compute or approximate
the topological structure of the sublevel-sets of the distance to a measure, in the same spirit as
what was done in the recent years for distances to compact sets. Such algorithms would naturally
find applications in topological inference in the presence of significant noise and outliers, but
also in other less obvious contexts such as stable clustering. The current bottleneck is that 
there exist no equivalents of the union of balls and alpha-shape in the case of the distance to
a measure. Our first goal will be to work out such equivalents that will allow to infer the homology of the underlying shape or more generally the topological persistence of the distance to measure functions.
%To start with, we will focus on
%medium dimensions and use a variant of the mesh-based inference algorithm [14] to approximate
%the sublevel-sets of the distance to a measure and get an idea of their topological structure.

\paragraph{Clustering with a geometric prior.} \framebox{add ref}
Clustering may be viewed as the most basic homology inference problem, since it consists in inferring the connected components in the data set. Typical methods for clustering data sets in high dimensions, {\it e.g.} spectral clustering, work well under three specific assumptions. First, the clusters should be sufficiently connected, for example, the second eigenvalue of their graph Laplacian should be large enough. Second, they should be well separated, that is, the interpoint distances between different clusters should be large enough on average. Third, the clusters should be balanced enough. We intend to develop methods that would take advantage of situations where the clusters have additional properties, such as being nearly convex or smooth, which seems reasonable in the large number of cases where manifold learning techniques apply. A promising strategy would be to use geometric regularity measures stemming from the geometric sampling theory recently introduced in \cite{geometrica-ccl09}. One challenge is to design these regularity measures in such a way that they are both easy to compute and amenable to classical clustering strategies. We expect the resulting clustering schemes to outperform classical spectral clustering when the data exhibit some form of geometric regularity. Byproducts of this effort could also lead to efficient algorithms for assessing the degree of geometric regularity present in real data. 



\paragraph{Topological signatures for shapes.}

Shape descriptors are used in a variety of applications, including
shape classification, shape retrieval, shape matching, shape
registration, and symmetry detection. In the context of this proposal,
the word {\em shape} must be understood in a very broad sense: for
instance, it can be a point cloud, or a
manifold, or more generally a compact metric space.

Using measured topological quantities to design signatures for shapes
is a relatively new idea. The bottom line of the approach is the
following: given a finite sampling of the shape, build some filtered
simplicial complex on top of the point cloud, and use the topological
structure of this filtration (encoded as a planar diagram called a
{\em persistence diagram}) as a signature for the point
cloud~\cite{ccgmo-ghsssp-09, socg-pbsds-10}. This construction is
well-suited for finite metric spaces, and the obtained signatures are
known to be stable under small perturbations of the spaces in the
Gromov-Hausdorff distance.  

A major remaining challenge is to extend the
construction to infinite metric spaces, and to prove the stability of
its topological structure with respect to perturbations of the space
in the Gromov-Hausdorff distance.

A more fundamental question is how much information about a shape can
be recovered from descriptors. Most existing work in shape analysis
only provides lower bounds on a shape distance (e.g. the
Gromov-Hausdorff distance) based on descriptor distance. There are
very few exceptions to this rule, and the upper bounds on shape
distances these provide come with very loose guarantees on the
error~\cite{bbk-gmds-06,ms-gh-05}. Deriving tight upper bounds is
thus still widely open, and we intend to tackle the problem as
follows: thanks to the virtually infinite variety of filtrations that
can be built on top of a shape, it is easy to enrich the pool of
signatures used for that shape, and thus restrict the possibility of
false positives in the shape comparison process. It is then a question
of how large a family of filtrations is required to guarantee that
different shapes do get different signatures. From an algorithmic
perspective, the problem comes down to identifying small samplings of this
family of filtrations that can be used as proxies for a better (if not
perfect) assessment of the similarity between two shapes.  As we
intend to consider our signatures on large sets of shapes, it will
also be important to design algorithms to efficiently compute these
signatures and compare them.% \framebox{shall we put a ref to
%  another WP where fast bottleneck distance computation/approximation
%  would be considered?}

Finally, the difficulty of matching two shapes is
intimately tied to matching a shape to itself --- shapes with many
natural self maps (symmetries) can be difficult to match because of
the ambiguities symmetries create (reflected in duplicate descriptors,
etc.). It may be interesting to define some sort of {\em condition
  number} for a shape, which would capture the intrinsic difficulty of
characteristic or matching against that shape.



