\thispagestyle{empty}

\mbox{}\vspace{-3.5cm}

\begin{center}
{\Large
{\bf ERC Advanced Grant 2012 \\ research proposal (PART B2)}}
\vspace{1cm}

{\LARGE {\bf  Algorithmic Foundations \\ of 
Geometry Understanding in Higher Dimensions}

\vspace{3mm} 

%{\bf (GUDHI)}
}
\end{center}
\section{The research proposal}

The central focus of this  proposal is  the computer analysis of geometric structures, which we refer to as {\em geometry understanding}. Our ambition is to settle the {\em algorithmic foundations} of geometry understanding  {\em in dimensions higher than 3}. We intend to develop new techniques to approximate highly nonlinear shapes, and to infer geometric and topological properties from data subject to significant {\em defects} and under {\em realistic conditions}. 
We will design {\em scalable representations} of complex shapes,  {\em practical and provably correct algorithms}, and we will deliver {\em perennial software}.

We now present the state of the art and the scientific objectives of our proposal that mirror its four main scientific challenges~: {\em choosing the right representation, bypassing the curse of dimensionality, searching for stable models, and turning theory into practice.}


\subsection{State of the art and scientific objectives}
%The last decade has seen tremendous progress in the understanding of geometry in high-dimensional spaces. 

\paragraph{Dimensionality reduction.} A widely accepted assumption in scientific computing and data analysis is that the objects of interest can be modeled as {\em low-dimensional manifolds}, even if they are embedded in high-dimensional ambient spaces. Low here is to be understood with respect to the ambient dimension and may be significantly higher than 3. This powerful assumption is supported by the fact that data are most of the time associated with physical systems that have relatively few parameters.  This assumption is valid accross science and engineering and is at the heart of dimensionality reduction and manifold learning.
%Examples can be found in fields as varied as chemistry~\cite{mtcw-tco-2010}, %neurosciences~\cite{} and  image processing~\cite{cids-lbsni-2008}.

{\em Dimensionality reduction} techniques intend to infer the intrinsic dimensionality of the data, as well as to provide structure-preserving mappings of the data into lower-dimensional spaces. {\em Nonlinear} dimensionality reduction techniques~\cite{lv-nldr-2007} are capable of discovering {nonlinear} structures and have been successfully applied to analyze data in a wide range of applications.
Nevertheless, the methods come with no or very limited guarantees. For example, Isomap~\cite{tsl-isomap-2000} provides a correct embedding only if the manifold is isometric to a convex open set of $\R ^k$, where $k$ is the estimated dimension of the manifold, and LLE~\cite{rs-lle-2000} can only reconstruct topological balls. {\em Topological methods} are complementary to dimension reduction methods. They intend to better approximate manifolds by constructing piecewise linear approximations, most of the time  in the form of simplicial complexes.

%However, they are only guaranteed to work on data sets sampled from manifolds with low curvature and trivial topology.
\vspace{2mm}  

{\bf Central objective :} {\em To develop geometric and topological methods for geometry understanding in higher dimensions.  To promote the use  of simplicial complexes as an expressive and powerful representation of shapes. }

\paragraph{Simplicial complexes.}  Simplicial complexes can be defined in any dimension and can be used as piecewise linear approximations of general shapes.
They have been extensively used in $\R ^3$ where surfaces or volumes are approximated by 2-dimensional or 3-dimensional simplicial complexes~\cite{geometrica-ecg-book}. 

The situation is quite different in higher dimensions. While simplicial simplexes have been studied for a long time by the mathematical community, the algorithmic side of the theory is still in its infancy. Most of the known simplicial complexes are either extremely difficult to compute even, in moderate dimensions, because their construction involves high-degree algebra (e.g., the  \v{C}ech complex) or easy to compute but so big that they cannot be constructed from real high-dimensional data (e.g., the Rips complex). Current research aims at finding new types of simplicial complexes that are easy to compute while still capturing the essential geometric and topological features of shapes. Recent progress has been made with the discovery of Delaunay-like complexes such as the witness complex~\cite{cds-tewc-2004} and the Delaunay tangential complex~\cite{geometrica-7142i} that offer new compromises between complexity and approximation quality.

 
Another issue is the {\em computer representation} of simplicial complexes. 
Little work has been done on the design of data structures for general
simplicial complexes. Brisson~\cite{Brisson:1989:RGS:73833.73858} and
Lienhardt~\cite{DBLP:journals/ijcga/Lienhardt94} have introduced data
structures to represent $d$-dimensional cell complexes. These data
structures are general and powerful, but very redundant, and they do
not scale to large data sets in high dimensions.  In contrast, one
could store only the 1-skeleton of the complex (edges and vertices). This 
saves a lot of memory space at the penalty of having to reconstruct the full complex when needed, e.g., to store a filtration. This can be done in a purely combinatorial way, thus very efficiently, in the special case of flag complexes (among which the Rips complex is a prominent example). Elaborating on this idea, Attali et al.~\cite{Attali2011} have proposed a concise data structure that is efficient when applied to simplicial complexes that are {\em close} to flag complexes. Still, designing efficient data structures to represent simplicial complexes is a widely open area.

% is enough to recover the full complex in the case of fl

% the special case of flag complexes (among which the Rips complex is a prominent example) are attractive since the full combinatorial structure is entirely determined by its 1-skeleton. This saves memory space at the penalty of having to reconstruct the full complex when needed, e.g., to store a filtration. Recently, Attali et al.~\cite{Attali2011} have proposed an efficient data structure to represent simplicial complexes that are close to flag complexes.
\vspace{2mm}

{\bf Objective 1:} {\em 
To extend  current knowledge of simplicial complexes, most notably their combinatorial and algorithmic properties.   To fully understand Delaunay-like simplicial complexes.  To design new  compact representation of simplicial complexes.}

\paragraph{Geometric approximation.}
In low dimensions, computing an approximation of a given geometric
object is a well-understood problem and good approximations can be
efficiently constructed~\cite{geometrica-bcmrv-ms-06,he-gtmg-2001}.
The situation is quite different in higher dimensions.  Although the
mathematical literature on triangulation of manifolds is abundant, few
effective algorithms have been proposed and tested.  The main issue is
to avoid computing a subdivision of the ambient space since this would lead to algorithms that scale exponentially with the ambient dimension. Very few attempts have been made to exploit the  low-dimensional manifold assumption.
To analyze {dynamical systems} in science and engineering, higher-dimensional {\em continuation methods} have been proposed to mesh solution manifolds~\cite{mh-mpc-2002}. These methods are however lacking guarantees and are restricted in practice to low dimensional manifolds. 
Recently, we made progress towards a better understanding of the complexity issues of triangulating smooth submanifolds and provided a provably correct algorithm that scales {\em linearly} with the ambient dimension~\cite{boissonnat2010meshing}. 

A natural way to bypass the curse of dimensionality is to directly
work on the manifold and to resort to {\em intrinsic geometry}. What
is lacking is a full development of Riemannian computational
geometry. A central question in our context, which has been elusive
for a long time, asks for the existence of Delaunay triangulations on
Riemannian manifolds. Previously announced sampling
criteria~\cite{leibon2000} for the existence of intrinsic Delaunay
triangulations have recently been demonstrated to be insufficient, and
sufficient criteria were introduced~\cite{boissonnat2012stab}. This opens exciting avenues for new developments on Delaunay triangulations in Riemannian manifolds and other non Euclidean spaces. Once again, what is profoundly lacking is the algorithmic side of the theory and the development of efficient, possibly approximate, algorithms.  A first promissing step towards this goal is an anisotropic meshing algorithm we proved correct and implemented~\cite{bwy-luam-08}.

Another fundamental problem is {\em manifold reconstruction}.  In low dimensions, effective reconstruction techniques exist that can provide a faithful approximation of a geometric structure from point samples~\cite{dey-csr-2007}. % Further processing makes it possible to study their topological and geometric properties.
Almost all these methods rely on the computational of a triangulation of the ambient space and previous attempts to extend them to higher dimensions led to algorithms whose complexities are exponential in the ambient dimension.  Despite some very recent results~\cite{geometrica-7142i}, designing practical algorithms that can reconstruct submanifolds of high-dimensional spaces under mild sampling conditions remains widely open. Extension beyond smooth manifolds 
is even more challenging.

% n addition to the computational bottleneck, 
%  the data often suffers from significant defects, including sparsity, noise, and outliers, violating sampling conditions required by extant methods. %  since their complexity depends exponentially on the ambient dimension

\vspace{2mm}

{\bf Objective 2 :}  {\em To   develop new algorithms to {\em  triangulate non Euclidean geometric spaces}. To study intrinsic Delaunay triangulations of Riemannian manifolds.  To reconstruct submanifolds using Delaunay-like simplicial complexes. To construct crude approximations 
with quality guarantees. To extend current knowledge on processing stratified manifolds. }

\paragraph{Geometric and topological inference.}
Since computing precise approximations is currently only possible under strong assumptions that may not be met in some applications, we can look for cruder approximations 
that can still  uncover some of the properties of the structures underlying the data.
%
%is not always mandatory. In some applications,   useful approximations can be obtained at a lower computational cost.
% In {\em robotics}, the goal is to capture the connectivity of configuration spaces and to search paths. Randomized techniques have been proved to be quite successful in constructing graphs to approximate the space of free configurations of robots~\cite{sml-pa-2006}. Those techniques are however limited to simple mechanical systems with no redundancy, no loop nor kinematic constraints. \framebox{check}
%In {\em topological data analysis}, 
%
A prominent example is homology that can be computed without a precise
reconstruction and under less restrictive
conditions~\cite{geometrica-ccl09,nsw-fhm-2008}. The rapidly growing
theory of {\em persistent homology}~\cite{eh-ph-2008,rg-bptd-2008} was
recently introduced as a powerful tool for the study of the
topological invariants of sampled shapes. The approach consists of
building a simplicial complex whose elements are filtered by some
user-defined function. The filtration is then used to remove
topological noise and to report the stable topological features.
These advances in computational topology attracted interest in the
mathematical community and in several fields like neurosciences,
computer vision or sensor
networks~\cite{fpgo-airc-2009,cids-lbsni-2008,dsrg-csnph-2007}.  What
still prevents these new methods from highly impacting applications is
the lack of efficient data structures and algorithms to construct
simplicial complexes and filtrations in high dimensions.

Another major issue is to design methods that are stable with respect
to {\em noise, sparsity, outliers and other defects} that corrupt data
and move them away from the underlying structure we want to
understand. The geometric approaches have so far only considered very restrictive models of noise~\cite{nsw-fhm-2008}.  Larger families of noise models have recently been considered and statistical approaches have been proposed to provide shape approximations that are stable with respect to those models~\cite{gpvw-mme-2011}. These methods however do not provide topological guarantees on the approximation and the question of designing computationally tractable estimators converging at an optimal rate remains open. A major challenge is to design unifying frameworks that embrace {\em statistical approaches} and deterministic methods, and offer topological guarantees.  

{\em Shape descriptors} are used in a variety of applications, including shape classification, shape retrieval, shape matching, shape registration, and symmetry detection.  Shape here must be understood in a broad sense and may be a point cloud, a manifold, or more generally, a compact metric set. A fundamental question is {\em how much information} about a shape can be recovered from descriptors. Most existing work in shape analysis only provides lower bounds on a shape distance (e.g. the Gromov-Hausdorff distance) based on descriptor distance. There are very few exceptions to this rule, and the upper bounds on shape distances these provide come with very loose guarantees on the error~\cite{bbk-gmds-06,ms-gh-05}. Deriving tight upper bounds is thus still widely open.  Descriptors based on topological quantities measured from a point cloud~\cite{ccgmo-ghsssp-09, socg-pbsds-10} opens new directions to explore. \framebox{check}



\vspace{2mm}

{\bf Objective 3 :} To study new {\em robust models for geometric and topological inference}.  To cluster data with a geometric prior. To study topological signatures of shapes.

\paragraph{Theory versus practice.} 
Geometric and topological methods are well behind dimensionality reduction techniques in terms of 
software development and applications.  
%
% Breaking the computational bottleneck is now the main issue.  Settling the {\em algorithmic foundations} of geometry understanding in
% higher dimensions is a grand challenge of great theoretical and practical significance.
%
To go beyond these low-dimensional examples, one needs efficient and robust software to construct and manipulate simplicial complexes in dimensions higher than 3.  Only a very few such software exist.  {\em Qhull} (http://www.qhull.org/) can compute convex hulls and Delaunay triangulations in moderate dimensions, but is of little use in the context of geometry understanding since it only constructs full-dimensional triangulations. {\em Multifario} (http://multifario.sourceforge.net/) is a set of subroutines and data structures dedicated to {\em meshing} manifolds that occur in dynamical systems. The software can in principle approximate manifolds or arbitrary codimension but examples are only reported in dimensions at most 3. Interestingly, this algorithm  uses a multiple parameter continuation approach and has some similarity with our algorithm~\cite{boissonnat2010meshing}, which has theoretical guarantees and whose complexity is only linear in the ambient dimension.  {\em Polymake} can handle several types of complexes, build Voronoi diagrams and compute advanced topological characteristics of objects like a finite representation of the fundamental group. It is however more oriented towards an interactive use for mathematical experimentation
rather than  an automated use at large scale.%, fast and robust data processing.
% C'est l'impression que j'en ai apres avoir un peu surfe sur differents
% sites, mais je n'ai pas une confiance absolue dans ce que je dis
% ci-dessus.

Several libraries exist for homology computation. RedHom computes Betti numbers and torsion coefficients of cubical sets, simplicial complexes and general, regular CW complexes (http://redhom.ii.uj.edu.pl/).
Two implementations of {\em persistent homology} algorithms are currently available, PLEX a package for Matlab (http://comptop.stanford.edu/u/programs/jplex/), and  Dionysus (www.mrzv.org/software/dionysus/). They both offer the construction of several types of simplicial complexes. PLEX has been  successfully applied in low dimensions~\cite{fpgo-airc-2009,rg-bptd-2008,mtcw-tco-2010}. Dionysus offers advanced
functionalities but there is no documentation and its diffusion is limited.
%Dionysus constructs $\alpha$-shapes, Cech and Rips complexes. Various options to compromize between memory and efficiency
%Plex : rips, landmark selection , ex k=1, d=25
\vspace{2mm}

{\bf Objective 4 :}   {\em To develop an open source {\em  software platform for geometric understanding in high dimensions}. %that will provide the software environment for experimenting with our new data structures and algorithms and to integrate them in a coherent library of interoperable modules. 
To apply our techniques to a few key problems where they may have a huge impact. To disseminate our software and to benchmark our results on real data from various applied fields.}

\subsection{Research roadmap} 


% This proposal addresses {\em fundamental
%   research} issues, and its results are expected to serve as a basis
% for groundbreaking advances for {\em applications in scientific computing
% and data analysis}. 
% A major outcome of the project will be a
% high-quality open source software {\em platform} of components
% implementing the main results. 
%


The proposal is structured into four areas that focus on objectives 1-4 mentionned above.
% which we now describe in more detail. 


\input{wp1}
\input{wp2}
\input{wp3}
\input{wp4}



\section{Resources}

\paragraph{Research environment.}
The PI and his research team, Geometrica, are part of INRIA, the french national institute for research in mathematics and informatics. Part of the group, including the PI, is located in the INRIA research center in Sophia Antipolis  (500 employees and 38 research groups) and part of the group is hosted by the INRIA research center in Saclay in Paris's area (26 research teams). Two members of the research center in Sophia Antipolis are members of the French Academy of Science, two have received an ERC advanced grant and two have received an ERC junior grant. Because of its partial location in Saclay, the group benefits from tight collaborations with the Ecole Normale Sup\'erieure and the Ecole Polytechnique. In particular, 4 members of the group teach at these prestigious institutions. Geometrica currently includes 10 permanent researchers,  2 postdoctoral researchers, 10 Ph.D. students, and 1 research engineer. 

\paragraph{The team members.}
The team members who are directly involved in this proposal are the PI (J-D. Boissonnat) and 2 permanent researchers of the Geometrica team : Fr\'ed\'eric Chazal and Mariette Yvinec.  J-D. Boissonnat will conduct and supervise the research activities of Gudhi and will be involved in the project for at least 70\% of his time.  Fr\'ed\'eric Chazal and Mariette Yvinec will each devote 20\% of their time to this project to co-supervise with the PI the research and implementation work of the students, postdocs and engineers to be engaged in this project. Fr\'ed\'eric Chazal, located in Saclay,  is a world expert in geometric inference and computational topology. Mariette Yvinec, located in Sophia Antipolis,  is a member of the CGAL Editorial Board. She  will be bring her unique expertise in geometric computing. Other members of Geometrica, not financially supported by this project, will also contribute to the ideas and expertise of Gudhi.

\paragraph{External team members.} We will establish a strong collaboration with F. Cazals, leader of the ABS research group on computational structural biology at INRIA Sophia Antipolis, to work on applications of geometry understanding in molecular biology (see Focus Area 4).

\paragraph{Available resources.} Our European ICT Fet-Open project Computational Geometric Learning (CG-Learning) will still be active until november 2013 for a maximum remaining amount of ??? Euros and will ensure a smooth start of Gudhi.  The ANR Pr\'esage (??? Keuros) will provide additional resources for the Geometrica activities in probabilistic techniques in geometry.

The Geometrica team is equipped with numerous PCs and has access to a large PC cluster owned by INRIA Sophia Antipolis.

\paragraph{Requested resources: personnal costs.}\mbox{}\\
-- 70\% of PI's salary over 5 years with a 70\% commitment of his time\\
-- 20\% of 2 PI's close collaborators over 5 years with a 20\% commitment of their time\\
-- 2 full-time post-doctoral researchers during the 5 years of the project\\
-- 2 full-time research engineers during 2.5 years covering the 5 years of the project\\
-- 1 full-time Ph.D. student during years 1, 2, 3\\
-- 1 full-time Ph.D. student during years 2, 3, 4\\
-- 1 full-time Ph.D. student during years 3, 4, 5\\
-- 4 men-months of invited professors in years 1-5.

\paragraph{Requested resources: other direct costs.}\mbox{}\\
-- travel \\
-- hardware : a multicore computer 5 KEuros

The rest of the costs consists of eligible indirect costs, at the rate of 20\% of the direct costs. \framebox{?}
The grand total amounts to ???? Euros over a period of 5 years, as detailed in the table below.

\framebox{include Table}

The funded 4 PhD students will have their research devoted to the fundamental aspects of the 3 first Focus Areas A1-A3 of this proposal, and one on the applications, co-advised with F. Cazals  (Focus Area 4). There will be a lot of synergy between their works, in particular in relation with the development of the platform. The funded research engineers  will help stabilize the software modules, as well as for the construction of new datasets to be made available to the scientific community.

We expect several researchers among our current partners (in particular in the CG-Learning project) to visit us each year and participate to Gudhi. We will also welcome talents from new groups who could bring a complementary expertise to the success of Gudhi. These visits will be funded in part by the ”invited professors” budget above, and in part by INRIA and other resources.
We will also organize a workshop early after the beginning of Gudhi to make it known to the international community, and to help attracting talented scientists for the success of Gudhi.

\newpage

{\small%footnotesize
%\bibliographystyle{alpha}
\bibliographystyle{apalike}
\bibliography{erc}
}

