\section{Research proposal (15p.)}

\subsection{State-of-the-art}%and objectives}

% Geometry understanding has undergone huge progress during the past decades. The pressing needs
% of multimedia, video games, numerical simulations, manufacturing, computer-aided medicine, cultural heritage and other applications asked for techniques to represent, process and analyze
% {\em 3D} shapes.  Progress has been contributed by  varied disciplines, most notably computer graphics, geometry processing, computer-aided design, computational geometry and topology, scientific computing. This considerable research effort resulted in solid theoretical and algorithmic foundations for 3D geometry understanding, and efficient algorithms and codes for applications such as surface reconstruction, mesh generation and point cloud processing~\cite{he-gtmg-2001,geometrica-bcmrv-ms-06,dey-csr-2007}.  
% The situation is very different and much less has been done for higher dimensional shapes.%   are much more difficult to handle than surfaces in 3-space for two main reasons~: the curse of dimensionality and the unafordable presence of noise.

The last decade has seen tremendous progress in the understanding of geometry in high-dimensional spaces. In this section, we discuss the models that have been used, their representation, the basic problems that have been identified, and how far the solutions stand from practical applications.

% highly accurate and efficient algorithms that capture and exploit the inherent structure of the model

% In robotics~\cite{sml-pa-2006}, randomized techniques have been proposed to capture the topology of configuration spaces and to search paths. In signal and image processing, and in machine learning, a variety of techniques have been proposed to reduce the dimension of data, learn nonlinear manifolds and cluster data~\cite{hs-fmmds-2006}. % In computational geometry, new approaches have been proposed to solve basic problems like searching nearest neighbours, computing smallest enclosing ellipsoids or approximating convex sets~\cite{hp-gaa-2011}.
% Most  of these methods have limited guarantees and 
% %address elementary questions (which may be very hard to solve though) and 
% impose strong constraints on the dimension or the topology of the shapes they can successfully handle. 

%  Deep mathematical results such as the Johnson-Lidenstrauss lemma and its recent variations in the context of compressed sensing~\cite{} also show that high-dimensional data can be projected onto lower dimensional subspaces without distorting much the interpoint distances, thus keeping most of the information.

\paragraph{Models and representation.} 
In  scientific computing and data analysis,  the objects of
interest can often be modeled as {\em low-dimensional manifolds}. This powerful assumption is supported by the fact that high-dimensional data are most of the time associated with physical systems that have few parameters.  Linear manifolds are the simplest and best studied types of geometric models, and the most popular in high-dimensional data analysis~\cite{hs-fmmds-2006,lv-nldr-2007}. {\em Spectral methods for dimensionality reduction} consists in mapping the data points down to a linear subspace, whose dimension supposedly coincides with the intrinsic dimension of the data. The mapping is obtained by computing an eigendecomposion of some matrix. This approach is elegant in that it helps detect the intrinsic parameters of the data, and by doing so it also reduces the complexity of the problem. Dimensionality reduction techniques fall into two classes: linear methods, e.g. principal component analysis (PCA) or multi-dimensional scaling (MDS), and non-linear methods, e.g. isomap or locally-linear embedding (LLE). The second class of algorithms is more powerful in that it computes more general (in fact, non-linear) mappings. On the whole, dimensionality reduction works well on data sets sampled from manifolds with low curvature and trivial topology. % Although the condition on the curvature is mainly a sampling issue, the condition on the topology is mandatory for the mapping onto a linear subspace to make sense. 

 To deal with highly nonlinear geometries, another route is to approximate shapes by {\em simplicial complexes}~\cite{hh-ct-2010}.  Simplicial complexes have been introduced by Poincar\'e in the early days of algebraic topology. Their importance in low dimensions cannot be overestimated~: 1-dimensional simplicial complexes, better known as graphs or networks, can be found everywhere,  2-dimensional simplicial complexes are the standard representations for surfaces in computer graphics and 3-dimensional simplicial complexes are the representation of choice for scientific computing and numerical simulation when complicated domains are involved. Simplicial complexes can be defined in any dimension and can be used to construct a piecewise linear approximation of a shape with the right topological type~\cite{geometrica-7142i} or to 
compute the homology of the shape~\cite{hh-ct-2010}. Simplicial complexes thus have the potential of being the data structure of choice for understanding geometry in high dimensional spaces. 

The main bottleneck in using simplicial complexes in higher dimensions is of a computational nature~:  in high dimensions, simplicial complexes can be huge and their construction may  involve algebraic operations of high degree. This makes  them very difficult to compute and limits their current use to low dimensions.
The question remains of how to define simplicial complexes that are dimension-sensitive and easy to compute.  Various types of simplicial complexes have been proposed such as the \v{C}ech and the Rips complexes, and more recent Delaunay-like complexes such as the $\alpha$-complex~\cite{eks-sspp-83,he-ubds-95}, the witness complex~\cite{deSilva2008,cds-tewc-2004} and the Delaunay tangential complex~\cite{geometrica-7142i}. They differ by their combinatorial and algorithmic complexities, and their power to approximate a shape.  The algorithmic theory of simplicial complexes is nevertheless in its infancy and much less developed than its counterpart for triangulations in small dimensions%~\cite{by-ag-98,he-gtmg-2001}. In particular, 
and little is known about efficient and compact representations of simplicial complexes% and,  up to now, experiments have only been %reported for simplicial complexes of low-dimensions
~\cite{Attali2011}. \framebox{true?} 


\paragraph{Geometry understanding.}
We distinguish three fundamental problems in geometry understanding~: approximation, reconstruction and topological inference.
In low dimensions, computing an approximation of a given geometric object is a well-understood problem and good approximations can be efficiently constructed~\cite{geometrica-bcmrv-ms-06,he-gtmg-2001}.  The situation is quite different in higher dimensions.  Although the mathematical literature on triangulation of manifolds is abundant, few effective algorithms have been proposed and experimented. 
To analyze {dynamical systems} in science or engineering, higher-dimensional {\em continuation methods} have been proposed to mesh solution manifolds~\cite{mh-mpc-2002}. These methods are however lacking guarantees and restricted in practice to low dimensional manifolds. A recent attempt to get rid of these restrictions can be found in~\cite{}.

Another fundamental problem is {\em manifold reconstruction}.  In low dimensions, effective reconstruction techniques exist that can provide a faithful approximation of a geometric structure from samples~\cite{dey-csr-2007}. % Further processing makes it possible to study their topological and geometric properties.
Extending those techniques to higher dimensions is a major challenge.  First, the data often suffers from significant defects, including sparsity, noise, and outliers, violating sampling conditions required by extant methods. The problem is further compounded by the rapid growth in complexity of the data structures used for reconstruction as the dimensionality of the data increases, making them intractable in high dimensions since their complexity depends exponentially on the ambient dimension. Despite some very recent results~\cite{geometrica-7142i}, designing practical algorithms to reconstruct submanifolds of high-dimensional spaces remains widely open.

Computing precise approximations of manifolds is not always mandatory. In some applications,   useful approximations can be obtained at a lower computational cost.
In {\em robotics}, the goal is to capture the connectivity of configuration spaces and allow to search paths. Randomized techniques have been proved to be quite successful in constructing graphs to approximate the space of free configurations of robots~\cite{sml-pa-2006}. Those techniques are however limited to simple mechanical systems with no redundancy, no loop nor kinematic constraints. \framebox{check}

In {\em topological data analysis}, important information can be recovered even if an accurate representation of the data is out of reach. In particular, infering the homology of the structures underlying the data is possible without full reconstruction and under less restrictive conditions~\cite{geometrica-ccl09,nsw-fhm-2008}. The rapidly growing theory of {\em persistent homology}~\cite{eh-ph-2008,rg-bptd-2008} was recently introduced as a powerful tool for the study of the topological invariants of sampled spaces. The approach consists in building a simplicial complex whose elements are filtered by some user-defined function. The filtration is then used to remove topological noise and to report the stable topological features.  These advances in computational topology attracted interest in the mathematical community and in several fields like data analysis, computer vision or sensor networks~\cite{rg-bptd-2008}. Again, the bottleneck that still prevents applications to benefit from the full potential of these new methods is the lack of efficient data structures and algorithms to construct simplicial complexes and filtrations in high dimensions, and the lack of methods that are provably stable with respect to  defect-laden inputs.


% \paragraph{Noisy data.} \framebox{to be revised}
% When dealing with approximation and samples, one needs stability results to ensure that the quantities that are computed, geometric or topological invariants, are good approximations of the real ones. {\em Topological persistence} was recently introduced as a powerful tool for the study of the topological invariants of sampled spaces~\cite{eh-ph-2008,rg-bptd-2008}. Given a point cloud in Euclidean space, the approach consists in building a simplicial complex whose elements are filtered by some user-defined function. This filter basically gives an order of insertion of the simplices in the complex. The persistence algorithm, first introduced by Edelsbrunner, Letscher and Zomorodian \cite{elz-tps-2002}, is able to track down the topological invariants of the filtered complex as the latter is being built. As proved by Cohen-Steiner et al. \cite{geometrica-cseh-07}, under reasonable conditions on the input point cloud, and modulo a right choice of filter, the most persistent invariants in the filtration correspond to invariants of the space underlying the data. Thus, the information extracted by the persistence algorithm is global, as opposed to the locality relationships used by the dimensionality reduction techniques. In this respect, topological persistence appears as a complementary tool to dimensionality reduction. In particular, it enables to determine whether the input data is sampled from a manifold with trivial topology, a mandatory condition for dimensionality reduction to work properly. Note however that it does not tell how and where to cut the data to remove unwanted topological features.

% Multiscale reconstruction is a novel approach~\cite{geometrica-bgo-09}. Taking advantage of the ideas of persistence, the approach consists in building a one-parameter family of simplicial complexes approximating the input at various scales. Differently from above, the family may not necessarily form a filtration, but it has other nice properties. In particular, for a sufficiently dense input data set, the family contains a long sequence of complexes that approximate the underlying space provably well, both in a topological and in a geometric sense. In fact, there can be several such sequences, each one corresponding to a plausible reconstruction at a certain scale. Thus, determining the topology and shape of the original object reduces to finding the stable sequences in the one-parameter family of complexes.   However, multiscale reconstruction, at least in its current form, still has a complexity that scales up exponentially with the dimension of the ambient space. Hence, it can only be applied to low-dimensional data sets in practice.


\paragraph{Software.}%The  virtuous circle  of research and development in computational geometry.}
Spectral methods for dimensionality reduction led to very successful software. 
The Matlab Toolbox for Dimensionality Reduction contains Matlab implementations of 33 techniques for dimensionality reduction and metric learning. Software for geometric and topological approaches are much less developed. Efficient solutions exist for basic geometric problems, e.g.
ANN, a widely used software to compute {\em approximate nearest-neighbors}. ANN implements a data structure based on hierarchical grids that adapt to the local density of data. Software that construct some types of simplicial complexes  also exist. QHULL can compute convex hulls and Delaunay triangulations in dimensions larger than 3, though it doesn't see much development anymore, and as the authors prominently announce on the webpage: ``Qhull does not support triangulation of non-convex surfaces, mesh generation of non-convex objects, medium-sized inputs in 9-D and higher, alpha shapes''. The {\em Polymake} framework can handle several types of complexes, build Voronoi diagrams and compute advanced topological characteristics of objects like a finite representation of the fundamental group. However, it is strongly oriented towards an interactive use for mathematical experimentation on a given object and not automated, fast and robust as needed in data processing.
% C'est l'impression que j'en ai apres avoir un peu surfe sur differents
% sites, mais je n'ai pas une confiance absolue dans ce que je dis
% ci-dessus.
{\em Multifario} is a set of subroutines and data structures for computing manifolds that occur in dynamical systems using a multiple parameter continuation approach. The software seems limited to manifolds of low dimension (examples are for dimensions up to 3). 

Only two implementations of {\em persistent homology} algorithms are currently available. One of them is the PLEX package for Matlab, developed by the Computational Topology group at Stanford University.  The other one is the library Dionysus proposed by Dmitriy Morozov. These implementations are known to be successful in small dimensions but inefficient as soon as the dimension rises.  Their maintenance, only assumed by the very few authors is likely not to be perennial.

The lack of reliable and efficient software is of course a major limitation towards a wide impact of topological methods. It may also be an indication that the current models are not the right ones and that the current theory of geometry understanding in higher dimensions has to be revised
in a more realistic setting.  The example of the CGAL library is instructive and will guide the research conducted in Gudhi. Our conviction is that, as the development of CGAL opened new avenues for research and triggered the wide diffusion of computational geometry methods in science and engineering, combining in a close way basic theoretical research and the development of a high-quality software environment will participate in the emergence of 
an effective theory of geometry understanding in higher dimensions and will lead to new ground breaking applications.

% Experimental research and implementation are by now major components of research in computational geometry.  

% % is the study of effective methods (algorithms and data structures) of geometric computing, namely methods that are not only theoretically proved but also work well in practice.  
% % Several EC projects (CGAL, GALIA) established an outstanding research momentum and gave a leading role to Europe in this context.  They led to successful techniques and tools, most notably 
% One of the major achievements of the field has been the CGAL library that provides a well-organised, robust and efficient software environment for developing geometric applications~\cite{cgal}. CGAL is by now the standard in geometric computing, with a large diffusion worldwide and varied applications in both academia and industry.  My research group at INRIA took a leading role in the development of CGAL since its start more than 10 years ago. More recently, we seconded our basic research on 3D shape processing by practical developments in the form of fast, safe and quality-guaranteed software components for mesh generation and shape reconstruction.  Those components  are now part of the open source library CGAL  and used worldwide in academia and in industry for various applications in geometric modeling, medical imaging and geology ~\cite{cgal:rty-m3-11}.. The functionalities of CGAL in higher dimensions are quite limited. Besides, only very few prototype software have been developed for geometry understanding in higher dimensions (see http://comptop.stanford.edu/programs/).

\subsection{Scientific objectives} 
This project is of a {\em fundamental nature} and its main objective is to settle the algorithmic foundations of geometric understanding in higher dimensions. To advance the state-of-the-art, we aim at processing general geometries represented as {\em simplicial complexes}. The computational bottleneck will be bypassed by assuming that the objects of interest are of {\em moderate intrinsic} dimension even if embedded in high dimensional spaces. We intend to develop {\em practical algorithms} to mesh or reconstruct highly nonlinear manifolds, and to infer geometric and topological properties from data subject to significant {\em defects} and
 under realistic conditions. A major outcome of the project will be a high-quality open source software {\em platform} of components implementing the main results.

% Processing and analyzing complex 3D shapes is a fundamental problem with a long history of scientific successes which is on the agenda of several communities like scientific computing, computer graphics, geometry processing and computer-aided design.  Emblematic problems are mesh generation that aims at sampling and meshing a given domain, and surface reconstruction that constructs an approximation of a surface which is only known through a set of points. During the last decade, the computational geometry community established solid theoretical foundations to these problems leading to recent breakthroughs in {\em mesh generation} \cite{geometrica-bcmrv-ms-06} and {\em surface reconstruction} \cite{dey-csr-2007}.  The Geometrica group took a leading role in this research and contributed major theoretical advances as well as practical developments in the form of fast, safe and quality-guaranteed software components for mesh generation and shape reconstruction that are now part of the open source library CGAL~\cite{cgal:rty-m3-11}. Those components are now used worldwide in academia and in industry for various applications in Geometric Modeling, Medical Imaging and Geology.





To reach our objectives, we will follow the principles that have been guiding my group for more than 10 years and will simultaneously develop
{\em mathematical approaches} providing guarantees even in the presence of noise or outliers,
{\em effective algorithms} that are amenable to theoretical analysis and fully validated experimentally,
and {\em perennial software} development.

\subsection{Scientific approach and methodology}

The proposal is structured into the following four workpackages:
{\bf WP 1}:  {\em Dimension-sensitive data  structures} will extend current knowledge about simplicial complexes, and  provide efficient data structures and basic algorithms for their representation, construction and manipulation. 
  {\bf WP 2}:  {\em Triangulating non Euclidean geometric spaces} will develop effective algorithms to mesh or reconstruct manifolds equipped with various metrics.   {\bf WP 3}: {\em Robust models for geometric inference, comparison and  clustering} will provide the crucial  algorithms for topological data analysis.
 {\bf WP 4}:  {\em  Software platform for geometric understanding in high dimensions} will provide the software environment for experimenting with our new data structures and algorithms, for integrating them in a coherent library of interoperable modules, and for diffusing our results to applied fields. We now describe in more detail each of these workpackages.


\input{wp1}
\input{wp2}
\input{wp3}
\input{wp4}


\bibliographystyle{abbrv}
\bibliography{erc}

\section{Resources}

\paragraph{Research environment.}
The PI and his research team, Geometrica, are part of INRIA, the french national institute for research in mathematics and informatics. Part of the group, including the PI, is located in the INRIA research center in Sophia Antipolis  (500 employees and 38 research groups) and part of the group is hosted by the INRIA research center in Saclay in Paris's area (26 research teams). Two members of the research center in Sophia Antipolis are members of the French Academy of Science, two have received an ERC advanced grant and two have received an ERC junior grant. Because of its location in Saclay, the group benefits from tight collaborations with the Ecole Normale Sup\'erieure and the Ecole Polytechnique. In particular, 4 members of the group teach at these prestigious institutions. Geometrica currently includes 10 permanent researchers,  2 postdoctoral researchers, 10 Ph.D. students, and 1 research engineer. 

\paragraph{The team members.}
The team members who are directly involved in this proposal are the PI (J-D. Boissonnat) and 2 permanent researchers of the Geometrica team : Fr\'ed\'eric Chazal and Mariette Yvinec.  J-D. Boissonnat will conduct and supervise the research activities of Gudhi and will be involved in the project for at least 70\% of his time.  Fr\'ed\'eric Chazal and Mariette Yvinec will devote 20\% of their time to this project to co-supervise with the PI the research and implementation work of the students, postdocs and engineers to be engaged in this project. Fr\'ed\'eric Chazal, located in Saclay,  is a world expert in geometric inference and computational topology. Mariette Yvinec, located in Sophia Antipolis,  is a member of the CGAL Editorial Board. She  will be bring her unique expertise in geometric computing. Other members of Geometrica, not financially supported by this project, will also contribute to the ideas and expertise of Gudhi.


\paragraph{Requested resources: personnal costs.}\mbox{}\\
-- 70\% of PI's salary over 5 years with a 70\% commitment of his time\\
-- 20\% of 2 PI's close collaborators over 5 years with a 20\% commitment of their time\\
-- 2 full-time post-doctoral researchers during the 5 years of the project\\
-- 2 full-time research engineers during 2.5 years covering the 5 years of the project\\
-- 1 full-time Ph.D. student during years 1, 2, 3\\
-- 1 full-time Ph.D. student during years 2, 3, 4\\
-- 1 full-time Ph.D. student during years 3, 4, 5\\
-- 4 men-months of invited professors in years 1-5.

\paragraph{Requested resources: other direct costs.}\mbox{}\\
-- travel \\
-- hardware : a multicore computer 5 KEuros

The rest of the costs consists of eligible indirect costs, at the rate of 20\% of the direct costs. \framebox{?}
The grand total amounts to ???? Euros over a period of 5 years, as detailed in the table below.

\framebox{include Table}


