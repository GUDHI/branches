\section{Research proposal}

The central goal of this proposal is to settle the {\em algorithmic foundations of geometry understanding in higher dimensions}.  We aim at processing general highly nonlinear geometries with nontrivial topologies that can be modeled as  {\em low-dimensional manifolds} embedded in possibly high-dimensional spaces. 

\subsection{State-of-the-art and objectives}
%The last decade has seen tremendous progress in the understanding of geometry in high-dimensional spaces. 

\paragraph{Dimensionality reduction.} A widely accepted assumption in scientific computing and data analysis is that the objects of interest can be modeled as {\em low-dimensional manifolds}, even if they are embedded in high-dimensional ambient spaces. Low here is to be understood with respect to the ambient dimension and may be significantly higher than 3. This powerful assumption is supported by the fact that data are most of the time associated with physical systems that have relatively few parameters.  This assumption is valid accross science and engineering and is at the heart of dimensionality reduction and manifold learning.
%Examples can be found in fields as varied as chemistry~\cite{mtcw-tco-2010}, %neurosciences~\cite{} and  image processing~\cite{cids-lbsni-2008}.

{\em Dimensionality reduction} techniques intend to infer the intrinsic dimensionality of the data, as well as to provide structure-preserving mappings of the data into lower-dimensional spaces. Nonlinear dimensionality reduction techniques~\cite{lv-nldr-2007} are capable of discovering nonlinear structures in the data and have been successfully applied to analyze data in a wide number of applications.
Nevertheless, the methods come with no or very limited guarantees. For example, Isomap~\cite{tsl-isomap-2000} provides a correct embedding only if the manifold is isometric to a convex open set of $\R ^k$, where $k$ is the estimated dimension of the manifold, and LLE~\cite{rs-lle-2000} can only reconstruct topological balls. {\em Topological methods} are complementary to dimension reduction methods. They intend to better approximate manifolds by constructing piecewise linear (PL) approximations in the form of simplicial complexes.

%However, they are only guaranteed to work on data sets sampled from manifolds with low curvature and trivial topology.

\paragraph{Simplicial complexes.}  Simplicial complexes can be defined in any dimension and can be used as piecewise linear approximations of general shapes.
Such representations have been extensively used in $\R ^3$ where surfaces or volumes are approximated by 2-dimensional or 3-dimensional simplicial complexes~\cite{geometrica-ecg-book}. 

Various types of simplicial complexes have been proposed such as the \v{C}ech and the Rips complexes, and more recent Delaunay-like complexes such as the $\alpha$-complex~\cite{he-ubds-95}, the witness complex~\cite{cds-tewc-2004} and the Delaunay tangential complex~\cite{geometrica-7142i}. These simplicial complexes differ by their power to approximate the geometry or the topology of a shape, its dimension, its homotopy type or its differential properties. Some simplicial complexes are embedded in the ambient space (such as the Delaunay-like simplicial complexes mentionned above) while others, such as the \v{C}ech and the Rips complexes, are not. They also differ by their combinatorial and algorithmic complexities. % Nevertheless, the simplicial complexes required to approximate complicated shapes in high dimensions are huge and their construction is problematic.
Some simplicial complexes like the \v{C}ech and the $\alpha$-complexes are extremely difficult to compute even in moderate dimensions while others like the Rips complex are easy to compute but their size is so big that they can be constructed from real high-dimensional data.  The recent Delaunay-like simplicial complexes offer interesting new compromises between complexity and approximation quality \cite{geometrica-7142i,cds-tewc-2004}.
%  First investigations led to very promising results, such as the design of new simplicial complexes with good complexity and approximation algorithms that scale well with the dimension 

{\bf Objective 1}:  to extend  current knowledge on simplicial complexes, most notably on their combinatorial and algorithmic properties, and   to design new  {\em intrinsic dimension-sensitive data  structures} to construct and store such simplicial complexes.

\paragraph{Geometric approximation.}
In low dimensions, computing an approximation of a given geometric object is a well-understood problem and good approximations can be efficiently constructed~\cite{geometrica-bcmrv-ms-06,he-gtmg-2001}.  The situation is quite different in higher dimensions.  Although the mathematical literature on triangulation of manifolds is abundant, few effective algorithms have been proposed and tested.  To analyze {dynamical systems} in science or engineering, higher-dimensional {\em continuation methods} have been proposed to mesh solution manifolds~\cite{mh-mpc-2002}. These methods are however lacking guarantees and are restricted in practice to low dimensional manifolds. 
We made recently some progress and proposed a provably correct algorithm to mesh smooth submanifolds~\cite{boissonnat2010meshing}.

Another fundamental problem is {\em manifold reconstruction}.  In low dimensions, effective reconstruction techniques exist that can provide a faithful approximation of a geometric structure from point samples~\cite{dey-csr-2007}. % Further processing makes it possible to study their topological and geometric properties.
Extending those techniques to higher dimensions is a major challenge.  First, the data often suffers from significant defects, including sparsity, noise, and outliers, violating sampling conditions required by extant methods. The problem is further compounded by the rapid growth in complexity of the data structures used for reconstruction as the dimensionality of the ambient space increases, which makes them intractable in high dimensions.%  since their complexity depends exponentially on the ambient dimension
 Despite some very recent results~\cite{geometrica-7142i}, designing practical algorithms that can reconstruct submanifolds of high-dimensional spaces under mild sampling conditions remains widely open.  

{\bf Objective 2 :}  to   develop new algorithms to {\em triangulate non Euclidean geometric spaces}, and to mesh or reconstruct manifolds equipped with various metrics.

\paragraph{Topological inference.}
Since computing precise approximations is currently only possible under strong assumptions that may not be met in some applications, we can look for cruder approximations 
that can still  uncover some of the properties of the structures underlying the data.
%
%is not always mandatory. In some applications,   useful approximations can be obtained at a lower computational cost.
% In {\em robotics}, the goal is to capture the connectivity of configuration spaces and to search paths. Randomized techniques have been proved to be quite successful in constructing graphs to approximate the space of free configurations of robots~\cite{sml-pa-2006}. Those techniques are however limited to simple mechanical systems with no redundancy, no loop nor kinematic constraints. \framebox{check}
%In {\em topological data analysis}, 
%
A prominent example is homology that can be computed  without a precise reconstruction and under less restrictive conditions~\cite{geometrica-ccl09,nsw-fhm-2008}. The rapidly growing theory of {\em persistent homology}~\cite{eh-ph-2008,rg-bptd-2008} was recently introduced as a powerful tool for the study of the topological invariants of sampled shapes. The approach consists of building a simplicial complex whose elements are filtered by some user-defined function. The filtration is then used to remove topological noise and to report the stable topological features.  These advances in computational topology attracted interest in the mathematical community and in several fields like neurosciences, computer vision or sensor networks~\cite{cids-lbsni-2008,rg-bptd-2008}. Again, the bottleneck that still prevents applications from benefiting of the full potential of these new methods is the lack of efficient data structures and algorithms to construct simplicial complexes and filtrations in high dimensions, and the lack of methods that are provably stable with respect to  noisy and defect-laden inputs.


% \paragraph{Stable models.} 
% When dealing with approximation and samples, one needs stability results to ensure that the quantities that are computed are good approximations of the real ones. This is especially true in higher-dimensions where data are usually corrupted by various types of noise.  When the noise is of small amplitude, methods have been proposed to robustly estimate topological and geometric properties of shapes~\cite{geometrica-ccl09,nsw-tvu-2011}. 
%  The recent and fast developing theory of {\em persistent homology} provides a powerful tool to study  the homology of sampled spaces~\cite{eh-ph-2008}.
% However, in  many applications the noise is non local and the previous methods fail.
% Recently,  larger families of noise models  have been considered and statistical approaches  have been proposed to approximate shape under  those models~\cite{gpvw-mme-2011}. These methods however do not provide topological guarantees on the approximation and do not always provide explicit estimates \framebox{check} . A major challenge is thus to design  unifying frameworks that embrace statistical approaches and deterministic methods, and offer topological guarantees.   Statistical techniques are also needed to automatically select the relevant scales at which the geometry of data should be considered. \framebox{un peu sec}

{\bf Objective 3 :} to study new {\em robust models for homology inference, comparison and  clustering}  and to provide the crucial  algorithms for topological data analysis.

\paragraph{Theory versus practice.} 
Geometric and topological methods are well behind dimensionality reduction techniques in terms of 
software development and applications.  
%
% Breaking the computational bottleneck is now the main issue.  Settling the {\em algorithmic foundations} of geometry understanding in
% higher dimensions is a grand challenge of great theoretical and practical significance.
%
To go beyong these low-dimensional examples, one needs efficient and robust software to construct and manipulate simplicial complexes in dimensions higher than 3.  Only a very few such software exist.  {\em Qhull} can compute convex hulls and Delaunay triangulations in moderate dimensions, but is of little use in the context of geometry understanding since it only constructs full-dimensional triangulations. {\em Multifario} is a set of subroutines and data structures dedicated to {\em meshing} manifolds that occur in dynamical systems using a multiple parameter continuation approach. The software can approximate 2 and 3-manifolds embedded in higher dimensional spaces. No theoretical guarantees nor extensive experiments are reported.  {\em Polymake} can handle several types of complexes, build Voronoi diagrams and compute advanced topological characteristics of objects like a finite representation of the fundamental group. It is however more oriented towards an interactive use for mathematical experimentation
rather than suited to an automated use at large scale.%, fast and robust data processing.
% C'est l'impression que j'en ai apres avoir un peu surfe sur differents
% sites, mais je n'ai pas une confiance absolue dans ce que je dis
% ci-dessus.

Several libraries exist for homology computation. RedHom computes Betti numbers and torsion coefficients of cubical sets, simplicial complexes and general, regular CW complexes using geometric reductions/coreductions and discrete Morse theory (http://redhom.ii.uj.edu.pl/).
Two implementations of {\em persistent homology} algorithms are currently available, PLEX a package for Matlab (http://comptop.stanford.edu/u/programs/jplex/), and  the Dionysus library (http://www.mrzv.org/software/dionysus/). They both offer the construction of several types of simplicial complexes. PLEX has been  successfully applied in low dimensions~\cite{fpgo-airc-2009,rg-bptd-2008,mtcw-tco-2010}. Dionysus offers advanced
functionalities (such as persistent cohomology computation and 
Zigzag persistent homology).
%Dionysus constructs $\alpha$-shapes, Cech and Rips complexes. Various options to compromize between memory and efficiency
%Plex : rips, landmark selection , ex k=1, d=25

{\bf Objective 4 :}   to develop a {\em  software platform for geometric understanding in high dimensions} that will provide the software environment for experimenting with our new data structures and algorithms, to integrate them in a coherent library of interoperable modules, and to diffuse our results to applied fields. 

\subsection{Research roadmap} 


% This proposal addresses {\em fundamental
%   research} issues, and its results are expected to serve as a basis
% for groundbreaking advances for {\em applications in scientific computing
% and data analysis}. 
% A major outcome of the project will be a
% high-quality open source software {\em platform} of components
% implementing the main results. 
%
To reach these objectives, the guiding principle  will be to simultaneously
develop {\em mathematical approaches} providing theoretical
guarantees, {\em effective algorithms} that are amenable to both
theoretical analysis and rigorous experimental validation, and {\em
  perennial software} development.


The proposal is structured into four areas that focus on the four objectives mentionned above, which we now describe in more detail. 


\input{wp1}
\input{wp2}
\input{wp3}
\input{wp4}



\section{Resources}

\paragraph{Research environment.}
The PI and his research team, Geometrica, are part of INRIA, the french national institute for research in mathematics and informatics. Part of the group, including the PI, is located in the INRIA research center in Sophia Antipolis  (500 employees and 38 research groups) and part of the group is hosted by the INRIA research center in Saclay in Paris's area (26 research teams). Two members of the research center in Sophia Antipolis are members of the French Academy of Science, two have received an ERC advanced grant and two have received an ERC junior grant. Because of its location in Saclay, the group benefits from tight collaborations with the Ecole Normale Sup\'erieure and the Ecole Polytechnique. In particular, 4 members of the group teach at these prestigious institutions. Geometrica currently includes 10 permanent researchers,  2 postdoctoral researchers, 10 Ph.D. students, and 1 research engineer. 

\paragraph{The team members.}
The team members who are directly involved in this proposal are the PI (J-D. Boissonnat) and 2 permanent researchers of the Geometrica team : Fr\'ed\'eric Chazal and Mariette Yvinec.  J-D. Boissonnat will conduct and supervise the research activities of Gudhi and will be involved in the project for at least 70\% of his time.  Fr\'ed\'eric Chazal and Mariette Yvinec will each devote 20\% of their time to this project to co-supervise with the PI the research and implementation work of the students, postdocs and engineers to be engaged in this project. Fr\'ed\'eric Chazal, located in Saclay,  is a world expert in geometric inference and computational topology. Mariette Yvinec, located in Sophia Antipolis,  is a member of the CGAL Editorial Board. She  will be bring her unique expertise in geometric computing. Other members of Geometrica, not financially supported by this project, will also contribute to the ideas and expertise of Gudhi.

\paragraph{External team members.} ??

\paragraph{Available resources.} Our European ICT Fet-Open project Computational Geometric Learning (CG-Learning) will still be active until november 2013 for a maximum remaining amount of ??? Euros and will ensure a smooth start of Gudhi.  The ANR Pr\'esage (??? Keuros) will provide additional resources for the Geometrica activities in probabilistic techniques in geometry.

The Geometrica team is equipped with numerous PCs and has access to a large PC cluster owned by INRIA Sophia Antipolis.

\paragraph{Requested resources: personnal costs.}\mbox{}\\
-- 70\% of PI's salary over 5 years with a 70\% commitment of his time\\
-- 20\% of 2 PI's close collaborators over 5 years with a 20\% commitment of their time\\
-- 2 full-time post-doctoral researchers during the 5 years of the project\\
-- 2 full-time research engineers during 2.5 years covering the 5 years of the project\\
-- 1 full-time Ph.D. student during years 1, 2, 3\\
-- 1 full-time Ph.D. student during years 2, 3, 4\\
-- 1 full-time Ph.D. student during years 3, 4, 5\\
-- 4 men-months of invited professors in years 1-5.

\paragraph{Requested resources: other direct costs.}\mbox{}\\
-- travel \\
-- hardware : a multicore computer 5 KEuros

The rest of the costs consists of eligible indirect costs, at the rate of 20\% of the direct costs. \framebox{?}
The grand total amounts to ???? Euros over a period of 5 years, as detailed in the table below.

\framebox{include Table}

The funded 4 PhD students will have their research devoted to the fundamental aspects of FA1, FA2 and FA3 of this proposal, and one on the applications. There will be a lot of synergy between their works, in particular in relation with the development of the platform. The funded research engineers  will help stabilize the software modules, as well as for the construction of new datasets to be made available to the scientific community.

We expect several researchers among our current partners (in particular in the CG-Learning project) to visit us each year and participate to Gudhi. We will also welcome talents from new groups who could bring a complementary expertise to the success of Gudhi. These visits will be funded in part by the ”invited professors” budget above, and in part by INRIA and other resources.
We will also organize a workshop early after the beginning of Gudhi to make it known to the international community, and to help attracting talented scientists for the success of Gudhi.


%\bibliographystyle{alpha}
\bibliographystyle{apalike}
\bibliography{erc}


